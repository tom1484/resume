// Configuration for this section
export const publicationsConfig = {
  infoLayout: 'inline', // 'inline' or 'standalone'
};

export const publications = [
  {
    title: "Advancing Structured Priors for Sparse-Voxel Surface Reconstruction",
    authors: ["Ting-Hsun Chi", "!Chu-Rong Chen", "Chi Tun Hsu", "Hsuan-Ting Lin", "Sheng-Yu Huang", "Cheng Sun", "Yu-Chiang Frank Wang"],
    publication: {
      conference: "CVPR 2026",
      status: "Under Review",
    },
  },
  {
    title: "Learning Skills from Action-Free Videos",
    authors: ["Hung-Chieh Fang*", "Kuo-Han Hung*", "!Chu-Rong Chen", "Po-Jung Chou", "Chun-Kai Yang", "Po-Chen Ko", "et al."],
    // authors: ["Hung-Chieh Fang*", "Kuo-Han Hung*", "!Chu-Rong Chen", "Po-Jung Chou", "Chun-Kai Yang", "Po-Chen Ko", "Yu-Chiang Frank Wang", "Yueh-Hua Wu", "Min-Hung Chen", "Shao-Hua Sun"],
    publication: {
      conference: "ICLR 2026",
      status: "Under Review",
    },
    // link: [
    //   { text: "Paper", url: "" },
    // ],
    // content: [
    //   "Developed Skill Abstraction from OpticalFlow (SOF), a framework that learns reusable robotic skills directly from action-free videos using optical flow as a proxy for actions.",
    //   "Enabled multitask learning and long-horizon planning by extracting and composing visual skills without requiring action-labeled data.",
    //   "Demonstrated improved performance across diverse tasks, showing the framework's effectiveness in learning from raw video data for generalist robot behavior.",
    // ],
    // tags: ["Video Understanding", "Skill Learning", "Optical Flow", "Multitask Learning", "Long-Horizon Planning"],
  },
];
